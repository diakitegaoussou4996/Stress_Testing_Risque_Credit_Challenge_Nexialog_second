{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52b4593",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"Bases/logoMoSEF.jpeg\" width=\"90px\" align=\"left\">\n",
    "  <div align=\"right\">Enseignant : Nexialog</div>\n",
    "  <div align=\"right\">Réalisé par : Seçil Coskun, ABABII Anisoara, Eunice KOFFI et DIAKITE Gaoussou</div>\n",
    "  <div align=\"right\">Année : 2022/2023</div>\n",
    "  <br><br><br>\n",
    "  <div align=\"center\">\n",
    "    <span style=\"font-family:Lucida Caligraphy;font-size:32px;color:darkgreen\">Master 2 Modélisation Statistiques Economiques et Financières</span>\n",
    "  </div>\n",
    "  <br>\n",
    "  <div align=\"center\">\n",
    "    <span style=\"font-family:Lucida Caligraphy;font-size:32px;color:darkgreen\">Université Paris 1 Panthéon-Sorbonne</span>\n",
    "  </div>\n",
    "  <br>\n",
    "  <div align=\"center\">\n",
    "    <span style=\"font-family:Lucida Caligraphy;font-size:28px;background-color:#F5DEB3;padding:5px;border-radius:10px\">Challenge Nexialog</span>\n",
    "  </div>\n",
    "  <br><br>\n",
    "  <hr>\n",
    "  <div align=\"center\">\n",
    "    <h1 style=\"font-size: 30px\">Partie 2 : Modèle</h1>\n",
    "    <p style=\"font-size: 24px;color:#696969\">Ce notebook présente le modèle BMA utilisé pour prédire le taux de défaut et les différents tests d'hypothèses appliqué.</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b23d9",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:20px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "IMPORTATION DES LIBRAIRIES</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5b53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sas7bdat import SAS7BDAT\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "%matplotlib inline\n",
    "from arch.unitroot import PhillipsPerron\n",
    "from scipy.stats import kendalltau\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from typing import List\n",
    "from statsmodels.tsa.stattools import adfuller, kpss \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import levene\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import itertools\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a344d0",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:20px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "IMPORTATION DE LA BASE DE DONNEES POUR LE MODELE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375dc83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_RGDP</th>\n",
       "      <th>gr_IRLT</th>\n",
       "      <th>gr_UNR</th>\n",
       "      <th>gr_RGDP_lag1</th>\n",
       "      <th>gr_RGDP_lag2</th>\n",
       "      <th>gr_RGDP_lag3</th>\n",
       "      <th>gr_RGDP_lag4</th>\n",
       "      <th>gr_IRLT_lag1</th>\n",
       "      <th>gr_IRLT_lag2</th>\n",
       "      <th>gr_UNR_lag1</th>\n",
       "      <th>gr_UNR_lag2</th>\n",
       "      <th>gr_UNR_lag3</th>\n",
       "      <th>gr_UNR_lag4</th>\n",
       "      <th>gr_HICP_lissee_lag2</th>\n",
       "      <th>gr_HICP_lissee_lag3</th>\n",
       "      <th>gr_HICP_lissee_lag4</th>\n",
       "      <th>DR_lag1</th>\n",
       "      <th>DR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-10-31</th>\n",
       "      <td>-0.024919</td>\n",
       "      <td>0.382664</td>\n",
       "      <td>0.276238</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.571053</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>-0.067907</td>\n",
       "      <td>-0.059051</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.048630</td>\n",
       "      <td>0.043486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>-0.032554</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.341834</td>\n",
       "      <td>-0.024919</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.382664</td>\n",
       "      <td>0.571053</td>\n",
       "      <td>0.276238</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>-0.067907</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.043242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-30</th>\n",
       "      <td>-0.032510</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.264994</td>\n",
       "      <td>-0.032554</td>\n",
       "      <td>-0.024919</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.382664</td>\n",
       "      <td>0.341834</td>\n",
       "      <td>0.276238</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.043242</td>\n",
       "      <td>0.040473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gr_RGDP   gr_IRLT    gr_UNR  gr_RGDP_lag1  gr_RGDP_lag2  \\\n",
       "Date                                                                   \n",
       "2011-10-31 -0.024919  0.382664  0.276238     -0.009517      0.005452   \n",
       "2012-01-31 -0.032554  0.173554  0.341834     -0.024919     -0.009517   \n",
       "2012-04-30 -0.032510  0.098901  0.264994     -0.032554     -0.024919   \n",
       "\n",
       "            gr_RGDP_lag3  gr_RGDP_lag4  gr_IRLT_lag1  gr_IRLT_lag2  \\\n",
       "Date                                                                 \n",
       "2011-10-31      0.015567      0.022698      0.571053      0.354839   \n",
       "2012-01-31      0.005452      0.015567      0.382664      0.571053   \n",
       "2012-04-30     -0.009517      0.005452      0.173554      0.382664   \n",
       "\n",
       "            gr_UNR_lag1  gr_UNR_lag2  gr_UNR_lag3  gr_UNR_lag4  \\\n",
       "Date                                                             \n",
       "2011-10-31     0.108471     0.020272    -0.067907    -0.059051   \n",
       "2012-01-31     0.276238     0.108471     0.020272    -0.067907   \n",
       "2012-04-30     0.341834     0.276238     0.108471     0.020272   \n",
       "\n",
       "            gr_HICP_lissee_lag2  gr_HICP_lissee_lag3  gr_HICP_lissee_lag4  \\\n",
       "Date                                                                        \n",
       "2011-10-31             0.022307             0.021585             0.018661   \n",
       "2012-01-31             0.026800             0.022307             0.021585   \n",
       "2012-04-30             0.030172             0.026800             0.022307   \n",
       "\n",
       "             DR_lag1        DR  \n",
       "Date                            \n",
       "2011-10-31  0.048630  0.043486  \n",
       "2012-01-31  0.043486  0.043242  \n",
       "2012-04-30  0.043242  0.040473  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Bases\\data_model.csv\", index_col=\"Date\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970de575",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Modèle BMA</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5b4da",
   "metadata": {},
   "source": [
    "Le modèle BMA (Bayesian Model Averaging) est une méthode qui permet de prendre en compte plusieurs modèles de régression linéaire et d'obtenir une prédiction en combinant les résultats de ces modèles. Dans ce notre cas, nous avons utilisé la bibliothèque statsmodels pour créer une boucle qui génère toutes les combinaisons possibles de variables explicatives à partir de notre base de données. Pour chaque combinaison, nous avons ajusté un modèle de régression linéaire en utilisant les variables explicatives et la variable cible DR. Ensuite, nous avons stocké chaque modèle dans une liste et avons calculé les prévisions correspondantes. La méthode BMA permet ensuite de pondérer les prévisions de chaque modèle pour obtenir une prédiction globale plus précise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61bc1e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "y_pred = []\n",
    "\n",
    "variables = [var for var in df.columns if var != \"DR\"]\n",
    "\n",
    "len(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(variables) + 1):\n",
    "    for combination in itertools.combinations(variables, i):\n",
    "        model = smf.ols(formula='DR ~ ' + ' + '.join(combination) + ' + 1', data=df).fit() # on rajoute '1' qui représente le constant dans le modèle\n",
    "        models.append(model)\n",
    "        y_hat = pd.DataFrame(model.predict(df[list(combination)]), columns = ['y'])\n",
    "        y_pred.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(models))\n",
    "print(2**len(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092d79e",
   "metadata": {},
   "source": [
    "Le nombre total de modèles générés pour le BMA est de 131071, où 131071 représente le nombre de combinaisons de variables possible à partir de la base de données fournie.\n",
    "p variables explicatives $\\rightarrow 2^p$ modèles possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e40b1b",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Significativité des coefficients</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d1a98",
   "metadata": {},
   "source": [
    "Cette étape permet de filtrer les modèles obtenus lors de la première étape en ne gardant que ceux ayant des coefficients statistiquement significatifs. Cela permet d'obtenir des modèles plus fiables et plus pertinents pour la prédiction du taux de défaut. La sortie affiche les résultats détaillés de chacun des modèles retenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_avec_coeffs_signif = []\n",
    "\n",
    "for i in range (0,len(models)):    \n",
    "    # Check if all p-values are less than 0.05\n",
    "    all_p_values_less_than_005 = True\n",
    "    for p_value in models[i].pvalues:\n",
    "        if p_value >= 0.05:\n",
    "            all_p_values_less_than_005 = False\n",
    "            break\n",
    "    if all_p_values_less_than_005:\n",
    "        models_avec_coeffs_signif.append(i)\n",
    "\n",
    "for elt in models_avec_coeffs_signif:\n",
    "    print(models[elt].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0160485",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_avec_coeffs_signif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddfa310",
   "metadata": {},
   "source": [
    "La liste des modèles avec des coefficients significatifs contient 222 modèles qui ont tous leurs coefficients avec des p-values inférieures à 0.05, indiquant une forte probabilité que les coefficients soient non nuls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e9010",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Tests des hypothèses économétriques</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04fe02",
   "metadata": {},
   "source": [
    "Voici l'étape suivante de notre étude :\n",
    "\n",
    "<div>\n",
    "<p>\n",
    "    Dans cette étape, nous allons vérifier si les modèles obtenus respectent les hypothèses de base de la régression linéaire multiple. \n",
    "</p>\n",
    "<ul>\n",
    "<li> Nous allons vérifier si les résidus ont une moyenne nulle : E(epsilon) = 0</li>\n",
    "<li> Sont indépendants les uns des autres cov(epsilon_i, epsilon_j) = 0 pour i différent de j</li>\n",
    "<li> Et sont homoscédastiques V(epsilon_i) = σ^2 : homoscédasticité</li>\n",
    "<li> Epsilon est un vecteur gaussien</li>\n",
    "<li>Nous allons également vérifier s'il n'y a pas de multicolinéarité entre les variables explicativesé</li>\n",
    "</ul>\n",
    "<p>\n",
    "Pour ce faire, nous allons appliquer des tests statistiques et enlever les modèles qui ne respectent pas les hypothèses.\n",
    "Nous allons également évaluer les métriques suivantes : RMSE, MSE, MAE, U-Theil, R2, R2 ajusté et intervalle de confiance. Le U-Theil est une métrique qui permet de mesurer la qualité de prédiction du modèle, mais il n'est pas souvent utilisé par les banques.\n",
    "</p>\n",
    "<p>\n",
    "Nous prendrons ensuite le meilleur modèle qui optimise les métriques (RMSE, U-Theil, R2, etc.) pour nos prévisions.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57169160",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    " Vérification de l'hypothèse 1 : $E(\\epsilon) = 0$</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3def00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models : \n",
    "    # Calculate the residuals\n",
    "    residuals = model.resid\n",
    "\n",
    "    # Plot the residuals against the predicted values\n",
    "    plt.scatter(model.predict(), residuals)\n",
    "    plt.axhline(y=0, color='red')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77370b",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    " Vérification de l'hypothèse 2 : $cov(\\epsilon_i, \\epsilon_j) = 0$ for i $\\neq$ j</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e228e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models : \n",
    "    # Calculate the residuals\n",
    "    residuals = model.resid\n",
    "    \n",
    "    # Calculate the variance-covariance matrix of the residuals\n",
    "    cov_matrix = np.cov(residuals)\n",
    "\n",
    "    # Print the variance-covariance matrix\n",
    "    print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf7f2d",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    " Vérification de l'hypothèse 3 : $V(\\epsilon_i) = \\sigma^2$  (homoscédasticité)</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce09983",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models : \n",
    "    plt.scatter(model.predict(), residuals ** 2)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Squared Residuals')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da1683",
   "metadata": {},
   "source": [
    " le test de white : \n",
    " \n",
    " $H_0 :  V(\\epsilon_i) = \\sigma^2$\n",
    " \n",
    "  $H_1 :  V(\\epsilon_i) = \\sigma_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_avec_resid_homosc = []\n",
    "\n",
    "for i in range (0,len(models)):    \n",
    "    # Calculate the residuals\n",
    "    residuals = models[i].resid\n",
    "\n",
    "    # perform White test\n",
    "    white_test = het_white(residuals, models[i].model.exog)\n",
    "    pvalue = white_test[1]\n",
    "    \n",
    "    if pvalue > 0.05:\n",
    "        modeles_avec_resid_homosc.append(i)\n",
    "    \n",
    "len(modeles_avec_resid_homosc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570b474",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Vérification de l'hypothèse 4 : $\\epsilon$ est un vecteur gaussien</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_norm = []\n",
    "\n",
    "for i in range (0,len(models)):    \n",
    "    # Calculate the residuals\n",
    "    residuals = models[i].resid\n",
    "\n",
    "    # Perform Shapiro-Wilk test\n",
    "    stat, p = shapiro(residuals)\n",
    "    # Interpret the results\n",
    "    if p > 0.05:\n",
    "        resid_norm.append(i)\n",
    "    \n",
    "len(resid_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e5f9c",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Vérification de l'hypothèse 5 : pas de multi colinéarité</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7aaff5",
   "metadata": {},
   "source": [
    "Nous pouvons détecter la multicollinéarité en utilisant le facteur d'inflation de la variance (FIV). Sans entrer dans trop de détails, l'interprétation du FIV est la suivante : la racine carrée du FIV d'une variable donnée montre de combien la taille de l'erreur standard est plus grande, comparée à ce qu'elle serait si ce prédicteur était non corrélé avec les autres caractéristiques du modèle. Si aucune caractéristique n'est corrélée, alors toutes les valeurs de FIV seront de 1.\n",
    "Pour traiter la multicollinéarité, nous devrions supprimer de manière itérative les caractéristiques avec des valeurs élevées de FIV. Une règle empirique pour la suppression pourrait être un FIV supérieur à 10 (5 est également courant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_sns_multicol = []\n",
    "\n",
    "for i in range (0,len(models)):    \n",
    "    params = list(models[i].params.index.drop(\"Intercept\"))\n",
    "    combination = df[params]\n",
    "    combination_cstt = add_constant(combination)\n",
    "    vif = [variance_inflation_factor(combination_cstt.values, j) for j in range(combination_cstt.shape[1])]\n",
    "    df_vif = pd.DataFrame({'vif': vif[1:]}, index=combination.columns)\n",
    "    \n",
    "    # check if any value in column is greater than 5\n",
    "    if (df_vif['vif'] > 5).any():\n",
    "        pass\n",
    "    else : \n",
    "        modeles_sns_multicol.append(i)\n",
    "            \n",
    "len(modeles_sns_multicol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9870bbb",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Sélection des modèles respectant les hypothèses</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5590cce",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons effectuer une intersection entre les modèles qui satisfont les hypothèses de coefficients significatifs, de résidus homoscédastiques, de résidus gaussiens et de non-multicolinéarité. Cette intersection nous permettra d'identifier les modèles qui répondent à toutes les hypothèses en même temps, et donc de retenir le meilleur modèle pour la suite de notre analyse. Pour cela, nous utilisons la fonction set() qui permet de créer un ensemble, et nous effectuons une intersection entre les différents ensembles correspondants à chaque hypothèse. Ensuite, nous transformons cet ensemble en liste pour une meilleure lisibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(models_avec_coeffs_signif).intersection(modeles_avec_resid_homosc, resid_norm, modeles_sns_multicol)\n",
    "intersection = list(intersection)\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464b663",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:25px;color:darkgreen\"> <span style=\"color:green\"> \n",
    "Au final, nous avons 62 modèles qui satisfont simultanément les critères de sélection suivants :</span></span></div>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:16px\">Les coefficients de régression sont significatifs (p-value inférieure à 0,05)</span></li>\n",
    "    <li><span style=\"font-size:16px\">Les résidus sont homoscédastiques</span></li>\n",
    "    <li><span style=\"font-size:16px\">Les résidus suivent une distribution normale</span></li>\n",
    "    <li><span style=\"font-size:16px\">Les variables indépendantes ne sont pas multicollinéaires</span></li>\n",
    "</ul>\n",
    "<span style=\"font-size:16px\">Nous avons obtenu ces modèles en faisant une intersection entre les modèles avec des coefficients significatifs, les modèles avec des résidus homoscédastiques, les modèles avec des résidus suivant une distribution normale et les modèles sans multicollinéarité. Le nombre de modèles qui satisfont simultanément tous ces critères est de 62.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f091175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in intersection:\n",
    "    model = models[elt]\n",
    "    print(elt, model.summary(), '\\n \\n \\n \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985a7df",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "U de Theil</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58530e94",
   "metadata": {},
   "source": [
    "L'étape suivante consiste à évaluer la qualité de notre modèle de prédiction en comparant ses prévisions avec une méthode naïve consistant à utiliser la valeur de la période précédente comme prédiction. Pour cela, on utilise l'U de Theil qui permet de mesurer la performance relative de notre modèle par rapport à cette méthode naïve. Si l'U de Theil est proche de 0 en valeur absolue, cela signifie que votre modèle est meilleur que l'estimateur naïf.*\n",
    "\n",
    "$$ \\text{U de Theil} = \\sqrt{\\frac{\\Sigma_{t=1}^T (\\frac{\\hat{y_t}-y_t}{y_{t-1}})^2}{\\Sigma_{t=1}^T (\\frac{y_t-y_{t-1}}{y_{t-1}})^2}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3554a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_rate2 = default_rate[8:] #pour qu'il est la même longueur que les y_pred\n",
    "def u2(forecast,actual):\n",
    "    num = ((forecast - actual)/ actual.shift(1))**2\n",
    "    denom = ((actual - actual.shift(1))/ actual.shift(1))**2\n",
    "    u = np.sqrt(np.sum(num)/np.sum(denom))\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a6957-15f9-4176-a797-1e37111e9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_retenus = []\n",
    "for elt in intersection:\n",
    "    if u2(y_pred[elt][\"y\"],default_rate2[\"DR\"]) < 1:\n",
    "        modeles_retenus.append(elt)\n",
    "        print(\"Le modèle {} a un U de Theil de {}\".format(elt, u2(y_pred[elt][\"y\"],default_rate2[\"DR\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f10a6",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Modèles retenus </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6854f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in modeles_retenus:\n",
    "    print(elt, models[elt].params, \"\\n\\n\")\n",
    "    \n",
    "#Les modeles retenus : \n",
    "# gr_UNR_lag3, DR_lag1 : modele 142\n",
    "# gr_UNR_lag4, DR_lag1 : 146\n",
    "# gr_RGDP_lag2, DR_lag1 : modele 86\n",
    "# gr_RGDP_lag3, DR_lag1 : 97\n",
    "# gr_RGDP_lag4, DR_lag1 : 107"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9e8de",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Sens économique</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[142].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accac312",
   "metadata": {},
   "source": [
    "# Interprétation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7bce4",
   "metadata": {},
   "source": [
    "Les résultats de notre modèle montrent que le taux de défaut retardé d'une période (DR_lag1) et le taux de chômage expliquent ensemble 95% de la variance du taux de défaut. De plus, ces variables sont toutes deux significatives, ce qui signifie qu'elles ont un impact significatif sur le taux de défaut. Enfin, le test de Fisher indique que le modèle est globalement significatif, ce qui renforce notre confiance dans sa capacité à expliquer le phénomène étudié.\n",
    "\n",
    "Il est important de noter que la valeur de l'Omnibus est inférieure à 5, ce qui suggère que les résidus sont distribués normalement. Le test de Jarque-Bera (JB) est également non significatif, ce qui soutient l'hypothèse de normalité des résidus. Le coefficient de Durbin-Watson est proche de 2, ce qui suggère qu'il n'y a pas de corrélation sérielle dans les résidus.\n",
    "\n",
    "Enfin, le modèle a un petit nombre d'observations (N=33), ce qui peut limiter sa généralisation à une population plus large. Il peut être intéressant d'explorer davantage les données pour voir si d'autres variables pourraient être incluses dans le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2aed7",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Stationnarité de $ DR_t-\\beta*DR_{t-1}$</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84186db9",
   "metadata": {},
   "source": [
    "Nous prenons des valeurs de beta comprises entre 0 et 1 (exclus). Nous évaluons si la différence entre drt et beta drt-1 est stationnaire en traçant les p-value pour chaque valeur de beta sur trois graphiques séparés : un pour le test ADF, un pour le test KPSS et un pour le test PP.\n",
    "\n",
    "Nous examinons chaque intervalle de beta pour lequel la série est stationnaire. Pour les trois tests, nous cherchons au moins deux intersections d'intervalles non vides. Nous pouvons alors conclure que la série est stationnaire si beta appartient à cet intervalle.\n",
    "\n",
    "Enfin, nous estimons la valeur de drt - beta drt-1 et nous vérifions que beta appartient à l'intervalle précédemment identifié comme correspondant à une série stationnaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3939a24",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Create an array of values for b</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31017a30",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons créer un ensemble de séries chronologiques en appliquant une régression linéaire entre la série chronologique originale et sa version décalée d'une période, pour différentes valeurs de beta allant de 0.01 à 0.99 avec un pas de 0.01.\n",
    "\n",
    "Nous allons stocker ces nouvelles séries chronologiques dans un DataFrame, en nommant chaque colonne selon la valeur de beta correspondante. Vous allons ensuite supprimer les valeurs manquantes (NaN) pour chaque colonne, car ces valeurs peuvent perturber les résultats des tests statistiques que vous allez effectuer par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beta = np.arange(0.01, 1, 0.01)\n",
    "df_vide = pd.DataFrame()\n",
    "# Fit the linear regression model for each value of b\n",
    "for b in beta:\n",
    "    ts = default_rate - b*default_rate.shift(1)\n",
    "    ts = ts.rename(columns = {\"DR\":\"{}\".format(b)})\n",
    "    df_vide = pd.concat([df_vide, ts], axis = 1)\n",
    "\n",
    "df_vide = df_vide.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationnarite_pvalues(data, vars_list):\n",
    "    res_df = pd.DataFrame(columns=['BETA', 'P-VALUE FOR ADF TEST',\n",
    "                                    'P-VALUE FOR PP TEST',\n",
    "                                   'P-VALUE FOR KPSS TEST'])\n",
    "    loop = 1\n",
    "    for x in vars_list:        \n",
    "        adf_result = adfuller(data[x])\n",
    "        pp_result = PhillipsPerron(data[x])\n",
    "        kpss_result = kpss(data[x])         \n",
    "        res_df = res_df.append({'BETA': x.upper(),\n",
    "                                'P-VALUE FOR ADF TEST': adf_result[1],\n",
    "                                'P-VALUE FOR PP TEST': pp_result.pvalue,\n",
    "                                'P-VALUE FOR KPSS TEST': kpss_result[1],\n",
    "                                '_i': loop}, ignore_index=True)\n",
    "        loop += 1\n",
    "    res_df = res_df.sort_values(by=['_i'])\n",
    "    del res_df['_i']\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = stationnarite_pvalues(df_vide, df_vide.columns)\n",
    "p_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"P-VALUE FOR ADF TEST\", \"P-VALUE FOR PP TEST\", \"P-VALUE FOR KPSS TEST\"]:\n",
    "    \n",
    "    p_values = p_values.sort_values(by=column)\n",
    "\n",
    "    # Plot the data\n",
    "    sns.lineplot(data=p_values, x=\"BETA\", y=column)\n",
    "\n",
    "    # Draw a horizontal line at y=0.05\n",
    "    plt.axhline(y=0.05, color='red', linestyle='--')\n",
    "\n",
    "    p_values[\"BETA\"] = p_values[\"BETA\"].astype(float)\n",
    "\n",
    "    # Get the x value where the horizontal line intersects the plot\n",
    "    x_intercept = np.interp(0.05, p_values[column], p_values[\"BETA\"])\n",
    "\n",
    "    # Draw a vertical line from the horizontal line to the x axis\n",
    "    plt.axvline(x=x_intercept, color='green', linestyle='--')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    print(x_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636feb8",
   "metadata": {},
   "source": [
    "# Commentaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b41ff8",
   "metadata": {},
   "source": [
    "En utilisant le test KPSS, on peut conclure que la série \"drt - beta drt-1\" est stationnaire lorsque \"beta\" appartient à l'intervalle [0.8323:1[. De même, en utilisant le test PP, on peut conclure que la série est stationnaire lorsque \"beta\" appartient à l'intervalle [0.643, 1[. Ainsi, on peut affirmer que la série \"drt - beta drt-1\" est stationnaire lorsque \"beta\" appartient à l'intervalle [0.8323:1[."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2424ba",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Estimatimation du taux de défaut </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03459c91",
   "metadata": {},
   "source": [
    "Dans cette partie on utilise la méthode d'estimation des moindres carrés ordinaires (OLS) pour estimer un modèle de régression linéaire qui lie le taux de défaut de la période actuelle à celui de la période précédente. Ensuite, en se basant sur les résultats des tests ADF, KPSS et PP effectués précédemment, on vérifie si le coefficient de régression beta obtenu appartient à l'intervalle [0.8323:1[ qui permet d'affirmer que la série temporelle est stationnaire. Le fait que la valeur de beta soit égale à 0.9250, qui appartient bien à l'intervalle déterminé, permet donc de conclure que la série est stationnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6556c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on estime drt - beta drt-1  et on verifie que beta appartienne à cet intervalle.\n",
    "model = smf.ols(formula='default_rate ~ default_rate.shift(1)' , data=default_rate).fit()\n",
    "model.summary()\n",
    "\n",
    "# 0.9250  appartient bien à [0.8323:1["
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e054a8",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Application du modèle sur les base sur des différents scénarios macroéconomiques</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92891cf",
   "metadata": {},
   "source": [
    "Dans cette partie, nous appliquons notre modèle à deux jeux de données: var_macro_adverse et var_macro_baseline. Pour chaque jeu de données, nous générons des scénarios de taux de croissance et réorganisons les données en renommant les colonnes et en ajustant les valeurs numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_taux = taux_croissance(var_macro_adverse)\n",
    "var_macro_adverse = pd.concat([scenarios_taux[\"gr_UNR\"], var_macro_adverse.drop(columns = [\"UNR\"])], axis = 1).dropna()\n",
    "var_macro_adverse = var_macro_adverse.rename(columns= {\"RGDP\":\"gr_RGDP\", \"HICP\":\"gr_HICP\", \"RREP\":\"gr_RREP\", \"IRLT\":\"gr_IRLT\"})\n",
    "var_macro_adverse[[\"gr_RGDP\" ,\"gr_HICP\" ,\"gr_RREP\"]] = var_macro_adverse[[\"gr_RGDP\" ,\"gr_HICP\" ,\"gr_RREP\"]] / 100\n",
    "var_macro_adverse[\"gr_IRLT\"] = var_macro_adverse[\"gr_IRLT\"] / 10\n",
    "\n",
    "scenarios_taux = taux_croissance(var_macro_baseline)\n",
    "var_macro_baseline = pd.concat([scenarios_taux[\"gr_UNR\"], var_macro_baseline.drop(columns = [\"UNR\"])], axis = 1).dropna()\n",
    "var_macro_baseline = var_macro_baseline.rename(columns= {\"RGDP\":\"gr_RGDP\", \"HICP\":\"gr_HICP\", \"RREP\":\"gr_RREP\", \"IRLT\":\"gr_IRLT\"})\n",
    "var_macro_baseline[[\"gr_RGDP\" ,\"gr_HICP\" ,\"gr_RREP\"]] = var_macro_baseline[[\"gr_RGDP\" ,\"gr_HICP\" ,\"gr_RREP\"]] / 100\n",
    "var_macro_baseline[\"gr_IRLT\"] = var_macro_baseline[\"gr_IRLT\"] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87028f2",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "Estimatimation de nos modèles rétenus </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_142 = smf.ols(formula='DR ~ gr_UNR_lag3 + DR_lag1  + 1', data=df).fit() #pour ne pas avoir à run le BMA\n",
    "model_142.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_86 = smf.ols(formula='DR ~ gr_RGDP_lag2 + DR_lag1  + 1', data=df).fit() #pour ne pas avoir à run le BMA\n",
    "model_86.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c4f47",
   "metadata": {},
   "source": [
    "<div align=\"left\"><span style=\"font-family:Lucida Caligraphy;font-size:30px;color:darkgreen\"> <span style=\"color:green\">      \n",
    "scénarios macroéconomiques. </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008f151",
   "metadata": {},
   "source": [
    "Les bases de données fournies pour nos tests comprennent des données trimestrielles pour les années 2018, 2019 et 2020. On constate que les valeurs pour chaque trimestre sont les mêmes dans les bases de données pour les deux scénarios, à savoir \"baseline\" et \"adverse\". Ces bases de données sont utilisées pour tester la capacité de notre modèle à prédire le taux de défaut.\n",
    "\n",
    "Nous allons utiliser ces deux bases de données pour produire des graphiques permettant de visualiser les prévisions de notre modèle pour les taux de défaut dans les scénarios \"baseline\" et \"adverse\". Les graphiques nous aideront à évaluer la performance de notre modèle et à déterminer s'il est capable de prédire de manière fiable les taux de défaut dans différents scénarios macroéconomiques.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th rowspan=\"2\">Date</th>\n",
    "      <th colspan=\"5\">Baseline</th>\n",
    "      <th colspan=\"5\">Adverse</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>RGDP</th>\n",
    "      <th>HICP</th>\n",
    "      <th>RREP</th>\n",
    "      <th>IRLT</th>\n",
    "      <th>UNR</th>\n",
    "      <th>RGDP</th>\n",
    "      <th>HICP</th>\n",
    "      <th>RREP</th>\n",
    "      <th>IRLT</th>\n",
    "      <th>UNR</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>2018-01-31</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.9</td>\n",
    "      <td>1.5</td>\n",
    "      <td>2.1</td>\n",
    "      <td>11.1</td>\n",
    "      <td>-0.6</td>\n",
    "      <td>0.8</td>\n",
    "      <td>-7.3</td>\n",
    "      <td>3.3</td>\n",
    "      <td>11.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2018-04-30</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.9</td>\n",
    "      <td>1.5</td>\n",
    "      <td>2.1</td>\n",
    "      <td>11.1</td>\n",
    "      <td>-0.6</td>\n",
    "      <td>0.8</td>\n",
    "      <td>-7.3</td>\n",
    "      <td>3.3</td>\n",
    "      <td>11.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2018-07-31</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.9</td>\n",
    "      <td>1.5</td>\n",
    "      <td>2.1</td>\n",
    "      <td>11.1</td>\n",
    "      <td>-0.6</td>\n",
    "      <td>0.8</td>\n",
    "      <td>-7.3</td>\n",
    "      <td>3.3</td>\n",
    "      <td>11.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2018-10-31</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.9</td>\n",
    "      <td>1.5</td>\n",
    "      <td>2.1</td>\n",
    "      <td>11.1</td>\n",
    "      <td>-0.6</td>\n",
    "      <td>0.8</td>\n",
    "      <td>-7.3</td>\n",
    "      <td>3.3</td>\n",
    "      <td>11.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2019-01-31</td>\n",
    "      <td>1.3</td>\n",
    "      <td>1.5</td>\n",
    "      <td>2.2</td>\n",
    "      <td>2.5</td>\n",
    "      <td>10.8</td>\n",
    "      <td>-1.5</td>\n",
    "      <td>0.8</td>\n",
    "      <td>-4.9</td\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da25ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphiques(var_macro_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphiques(var_macro_adverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71a350",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Modèle 1</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959ef4b",
   "metadata": {},
   "source": [
    "On applique le même traitement fait sur la base var_macro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_modele_142(scenario) : \n",
    "    sc = create_lags_diffs(scenario, num_lags = 3)\n",
    "    X1 = sc[\"gr_UNR_lag3\"] \n",
    "    X = pd.concat([X1, df[-1:][\"DR_lag1\"], df[-1:][\"DR\"]], axis = 1) #on rajoute la 2ème variable explicative\n",
    "    dates =  X.index.date.astype(str).tolist()\n",
    "    \n",
    "    for i in range (len(dates)-1) :\n",
    "        X_1 = X.loc[dates[i]] # au début on retient juste 2019-10-31 pour calculer la date d'apres, etc.\n",
    "        sc_predictions = model_142.predict(X_1)\n",
    "        sc_predictions = pd.DataFrame(sc_predictions, columns = [\"DR_pred\"])\n",
    "        X.loc[dates[i+1]]['DR'] = sc_predictions[\"DR_pred\"]\n",
    "        X[\"DR_lag1\"] = X[\"DR\"].shift(1)\n",
    "        \n",
    "    serie_predite = X.loc[X.index > '2019-10-31'][\"DR\"]\n",
    "    serie_predite_et_val_precente = X.loc[X.index > '2019-07-31'][\"DR\"] #pour qu'il y ait pas de trou dans le plot dû aux dates\n",
    "    return serie_predite, serie_predite_et_val_precente\n",
    "\n",
    "def plot_modele_142(scenario) : \n",
    "    plt.plot(default_rate, label='Série originale')\n",
    "    plt.plot(prediction_modele_142(scenario)[1], label='Série prédite')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_modele_142(var_macro_adverse)\n",
    "\n",
    "# 2020-01-31    0.030860\n",
    "# 2020-04-30    0.029303\n",
    "# 2020-07-31    0.031741\n",
    "# 2020-10-31    0.030438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_142(var_macro_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_142(var_macro_adverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe2983",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Modèle 2</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa963fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction_modele_86(scenario) : \n",
    "    sc = create_lags_diffs(scenario, num_lags = 3)\n",
    "    X1 = sc[\"gr_RGDP_lag2\"] \n",
    "    X = pd.concat([X1, df[-1:][\"DR_lag1\"], df[-1:][\"DR\"]], axis = 1) #on rajoute la 2ème variable explicative\n",
    "    dates =  X.index.date.astype(str).tolist()\n",
    "    \n",
    "    for i in range (len(dates)-1) :\n",
    "        X_1 = X.loc[dates[i]] # au début on retient juste 2019-10-31 pour calculer la date d'apres, etc.\n",
    "        sc_predictions = model_86.predict(X_1)\n",
    "        sc_predictions = pd.DataFrame(sc_predictions, columns = [\"DR_pred\"])\n",
    "        X.loc[dates[i+1]]['DR'] = sc_predictions[\"DR_pred\"]\n",
    "        X[\"DR_lag1\"] = X[\"DR\"].shift(1)\n",
    "        \n",
    "    serie_predite = X.loc[X.index > '2019-10-31'][\"DR\"]\n",
    "    serie_predite_et_val_precente = X.loc[X.index > '2019-07-31'][\"DR\"] #pour qu'il y ait pas de trou dans le plot dû aux dates\n",
    "    return serie_predite, serie_predite_et_val_precente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_modele_86(scenario) : \n",
    "    plt.plot(default_rate, label='Série originale')\n",
    "    plt.plot(prediction_modele_86(scenario)[1], label='Série prédite')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_86(var_macro_adverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ff609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_86(var_macro_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885fdf3",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:green\">\n",
    "<center><h1>Modèle 3 : Stacking</h1></center>\n",
    "<hr style=\"border-width:2px;border-color:green\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_142 = model_142.predict(df)\n",
    "y_hat_86 = model_86.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de901291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#et si on les stackait ?\n",
    "\n",
    "# Stack the predictions into a matrix\n",
    "preds_stacked = np.column_stack((y_hat_142, y_hat_86))\n",
    "\n",
    "# Fit a new OLS model using the stacked predictions\n",
    "dr = default_rate[7:]\n",
    "model_stacked = sm.OLS(dr, preds_stacked).fit()\n",
    "\n",
    "# Print the summary statistics for the new model\n",
    "print(model_stacked.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stacked.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_modele_stacking(scenario) :\n",
    "\n",
    "\n",
    "    # Get the predictions from each of the original models for the new data\n",
    "    preds1_new = prediction_modele_86(scenario)[1]\n",
    "    preds2_new = prediction_modele_142(scenario)[1]\n",
    "\n",
    "    # Stack the new predictions into a matrix\n",
    "    preds_stacked_new = np.column_stack((preds1_new, preds2_new))\n",
    "\n",
    "    # Make predictions using the stacked model\n",
    "    y_pred_stacked = model_stacked.predict(preds_stacked_new)\n",
    "    y_pred_stacked = pd.DataFrame(y_pred_stacked, columns = [\"DR\"])\n",
    "    index_values = ['2019-10-31','2020-01-31','2020-04-30','2020-07-31','2020-10-31']\n",
    "    y_pred_stacked['index'] = index_values\n",
    "    y_pred_stacked = y_pred_stacked.set_index('index')\n",
    "    y_pred_stacked.index = pd.to_datetime(y_pred_stacked.index)\n",
    "    return y_pred_stacked\n",
    "\n",
    "def plot_modele_stacking(scenario) : \n",
    "    plt.plot(default_rate, label='Série originale')\n",
    "    plt.plot(pred_modele_stacking(scenario), label='Série prédite')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f19bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_stacking(var_macro_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51279ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_modele_stacking(var_macro_adverse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
